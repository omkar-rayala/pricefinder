{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNNm/qbJfNqWwSLb+OqJ00G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkar-rayala/pricefinder/blob/main/price.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeHjJiLrVzHf"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import pandas as pd\n",
        "import webbrowser as wb\n",
        "import time\n",
        "\n",
        "headers={\n",
        "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'\n",
        "}\n",
        "def flipkart(product):\n",
        "    uri = \"https://www.flipkart.com/search?q={}&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\".format(product)\n",
        "    req = requests.get(uri,headers=headers)\n",
        "    html = req.text\n",
        "    soup = bs(html,'html.parser')\n",
        "    baseurl=\"https://www.flipkart.com\"\n",
        "    names1=[]\n",
        "    prices1=[]\n",
        "    urls=[]\n",
        "    offers=[]\n",
        "    \n",
        "    h= soup.find_all(\"div\", {\"class\": \"_2kHMtA\"})\n",
        "    \n",
        "    if not h:\n",
        "        h=soup.find_all(\"div\", {\"class\":\"_4ddWXP\"})\n",
        "        for i in h:\n",
        "            for j in i.find_all(\"a\", {\"class\": \"s1Q9rs\"}):\n",
        "                names1.append(j.text.replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").replace(\"-\",\"\"))\n",
        "            for k in i.find_all(\"div\", {\"class\":\"_30jeq3\"}):\n",
        "                prices1.append(k.text.replace(\"₹\",\"\").replace(\",\",\"\"))\n",
        "            for link in i.find_all(\"a\",href=True):\n",
        "                urls.append(baseurl+link['href'])\n",
        "    else:\n",
        "        for i in h:\n",
        "            for j in i.find_all(\"div\", {\"class\": \"_4rR01T\"}):\n",
        "                names1.append(j.text.replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").replace(\"-\",\"\"))\n",
        "            for k in i.find_all(\"div\", {\"class\":\"_30jeq3 _1_WHN1\"}):\n",
        "                prices1.append(k.text.replace(\"₹\",\"\").replace(\",\",\"\"))\n",
        "            for link in i.find_all(\"a\",href=True):\n",
        "                urls.append(baseurl+link['href'])\n",
        "    #urls=urls[:10]\n",
        "    for i in urls:\n",
        "        req = requests.get(i,headers=headers)\n",
        "        html = req.content\n",
        "        soup = bs(html,'html.parser')\n",
        "        offer= soup.find(\"li\",{\"_16eBzU col\"})\n",
        "        offers.append(offer)\n",
        "                \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    df1=pd.DataFrame({'model': pd.Series(names1), 'price': pd.Series(prices1),'offers':pd.Series(offers)})\n",
        "    df1=df1.dropna()\n",
        "    return df1\n",
        "\n",
        "\n",
        "def amazon(product):\n",
        "    \n",
        "    uri = \"https://www.amazon.in/s?k={}&ref=nb_sb_noss_2\".format(product)\n",
        "    req = requests.get(uri,headers=headers)\n",
        "\n",
        "    html = req.text\n",
        "    soup = bs(html,'html.parser')\n",
        "    \n",
        "    baseurl=\"https://www.amazon.in\"\n",
        "    names1=[]\n",
        "    prices1=[]\n",
        "    urls=[]\n",
        "    offers=[]\n",
        "    \n",
        "    h= soup.find_all(\"div\", {\"class\": \"a-section a-spacing-medium\"})\n",
        "    for i in h:\n",
        "        if (i.find_all(\"span\", {\"class\": \"a-color-secondary\"})!=\"Sponsored\"):\n",
        "            if not(i.find_all(\"span\", {\"class\": \"a-size-base-plus a-color-base a-text-normal\"})):\n",
        "                for j in i.find_all(\"span\", {\"class\": \"a-size-medium a-color-base a-text-normal\"}):\n",
        "                    names1.append(j.text.replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").replace(\"-\",\"\"))\n",
        "            else:\n",
        "                for j in i.find_all(\"span\", {\"class\": \"a-size-base-plus a-color-base a-text-normal\"}):\n",
        "                    names1.append(j.text.replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").replace(\"-\",\"\"))\n",
        "            for k in i.find_all(\"span\", {\"class\":\"a-price-whole\"}):\n",
        "                prices1.append(k.text.replace(\"₹\",\"\").replace(\",\",\"\"))\n",
        "            for link in i.find_all(\"a\",{\"class\":\"a-link-normal a-text-normal\"},href=True):\n",
        "                urls.append(baseurl+link['href'])\n",
        "    #urls=urls[:10]\n",
        "    for i in urls:\n",
        "        req = requests.get(i,headers=headers)\n",
        "        html = req.content\n",
        "        soup = bs(html,'html.parser')\n",
        "        offer= soup.find(\"span\",{\"class\":\"description\"})\n",
        "        if not offer:\n",
        "            offer= soup.find(\"li\",{\"class\":\"a-spacing-small a-spacing-top-small\"})\n",
        "#         for j in offer:\n",
        "        offers.append(offer)\n",
        "\n",
        "    df2=pd.DataFrame({'model': pd.Series(names1), 'prices': pd.Series(prices1),'offers':pd.Series(offers)})\n",
        "    df2=df2.dropna()\n",
        "    return df2\n",
        "\n",
        "start_time=time.time()\n",
        "product=input(\"product name:\")\n",
        "df2=amazon(product)\n",
        "df1=flipkart(product)\n",
        "result=pd.concat([df2,df1],keys=[\"Amazon\", \"Flipkart\"],axis=1)\n",
        "stop_time=time.time()\n",
        "print(\"Time taken {}\".format(stop_time-start_time))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}